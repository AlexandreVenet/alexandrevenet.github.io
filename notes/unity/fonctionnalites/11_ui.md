# *UI* Fondamentaux

Le 18-10-2021

Notes des cours *Unity 2018 UI Fundamentals* et 3WA.

## Types d'interfaces

Les **interfaces graphiques** sont distinguées selon qu'elles sont **dans l'espace 3D ou non** et qu'elles **existent ou non dans le monde du jeu** :
- l'*UI* est ***diegetic*** lorsque les objets d'UI font partie de **l'espace 3D et du monde du jeu**. Elle suppose que le **joueur sache** où se trouvent ces objets. Exemple : un point de sauvegarde,
- l'*UI* est ***non-diegetic*** lorsqu'il est fait usage d'un calque ou d'une couche d'*UI* (*overlay UI*) **en dehors de l'espace 3D et du monde du jeu**. C'est non le personnage joué qui intervient dessus mais l'**utilisateur**. Exemple : un HUD, un panneau de meilleurs scores visible par l'utilisateur seulement,
- l'*UI* est ***spatial*** lorsqu'elle est une chose **dans le monde 3D** du jeu mais qui **ne fait pas sens pour le monde du jeu**. Exemple : particules ou *shaders* qui indiquent d'autres joueurs ou un lieu à atteindre ou son propre personnage jouable,
- l'*UI* est ***meta*** lorsqu'elle est une chose **dans le monde du jeu** mais **pas dans l'espace 3D** et dont **le joueur semble ne pas considérer**. Exemple : traces d'eau de pluie sur la caméra que le personnage joué ignore complètement (sait-il qu'il est suivi par une caméra ?) mais que l'utilisateur considère.

## *Canvas*

Créer un `UI > Canvas` dans la scène. Cela ajoute un objet `EventSystem` nécessaire au fonctionnement et qui gère les événements utilisateur. On peut aussi ajouter dans la scène un `GameObject` déjà paramétré avec un composant d'*UI*, ce qui provoque automatiquement la création d'un *canvas* et de l'objet d'*UI* choisi à l'intérieur.

Un **canevas ou une toile (*canvas*)** est ce qu'utilise Unity pour afficher l'*UI*. Par défaut, ce *canvas* correspond à la taille de l'écran définie dans la fenêtre *Game*.

Ce *canvas* possède des `Render modes` :
- le ***Screen Space - Overlay*** : couche ou vignette utilisée **à l'écran au-dessus de tout**. Si on met un `GameObject` 3D enfant du *canvas*, on ne le voit pas ; si on le met enfant de la caméra, on le voit,  
- le ***Screen Space - Camera*** : couche utilisée **dans la vue de la caméra**, associée à la caméra. Il faut renseigner la caméra dans un champ `Render Camera`. Ce *canvas* est projeté à une certaine distance de la caméra. La caméra verra un HUD à cette distance ; donc pour que le HUD soit visible :
	- modifier le `Clipping Plane : Far` de la caméra (ex : 10 en `Projection` perspective),
	- **ET** modifier le `Plane Distance` du *canvas* (ex : 5).
- le ***World Space*** : les objets d'*UI* sont vus dans le monde. Cela autorise toutes sortes de manipulations en 3D des objets d'*UI* : plans dans le décor, bulles de dialogues... Limite : l'objet d'*UI* est une surface, donc possède une normale, donc il faut penser comment résoudre le problème des plans vus d'une face mais pas de l'autre.

## Résolutions

On **exporte** (***build***) un projet pour **différentes résolutions** selon le terminal utilisé. Par exemple : PC : haute résolution ; HTML5 web : intermédiaire ; mobile horizontal/vertical...

Ces résolutions peuvent être définies pour le produit final dans `File > Build settings...`. On y choisit la **destination**.

Cliquer sur `Player settings` et sur l'encart `Resolution and Presentation`. Dans les `Supported Aspect Ratios`, on peut sélectionner les rapports qui nous intéressent selon la destination du projet. Or, ici on ne voit pas les effets de ces choix. 

Pour voir l'effet des choix de résolution et ratios, aller dans la fenêtre *Game* et dans son menu, choisir les rapports disponibles pour cette destination (on peut ajouter d'autres résolutions et rapports en cliquant sur `+`).

Par exemple, si on veut exporter pour 16:9 à 1280x720px, il se peut qu'on ne voit qu'une partie du *canvas* d'*UI* et non plus sa totalité. Pour résoudre ce problème, on peut paramétrer le *canvas* de façon à ce qu'il s'adapte à la résolution de sortie :
- sélectionner le *canvas* et consulter le composant `Canvas Scaler`,
- dans `UI Scale Mode`, choisir `Scale with screen size`,
- dans la `Reference resolution` indiquer la résolution 1280x720. Cela pose, à titre indicatif, la définition de travail, celle pour laquelle l'*UI* a été réalisée,
- il peut être nécessaire de poser le `Match` à 0.5 : association de la hauteur et de la largeur.

Une autre possibilité est de choisir `UI Scale Mode : Constant Pixel Size` et de modifier le `Scale Factor` de façon à gérer l'affichage (cela peut améliorer le lissage texte).

Une fois ces paramètrages effectués, on `Build` au ratio 16:9. 

Pour exporter en **WebGL**, on peut définir la **résolution du *canvas* web**. 

Pour exporter sur **Android**, d'autres paramètres de `Resolution and Presentation` sont disponibles :
- `Aspect ratio mode` : défini ou personnalisé (utilise un `float`),
- `Orientation` : auto, portrait...
- `Allowed orientations for auto rotation` : si le paramètre précédent est `auto`.

## Composants 

Les objets d'*UI* sont nombreux et leur avantage est qu'ils se prêtent très bien à la déformation, *a contrario* des objets 3D dont les transformations risquent de nuire au fonctionnement ou au rendu (*collider*, texture... ). Les déformations s'effectuent avec l'outil `Rect Tool` (touche `T`).

Les objets 3D ont un composant `transform` ; en *UI*, les objets sont aussi en 3D mais sans épaisseur et ont un `Rect Rransform`. Ce composant fournit le nécessaire pour positionner et redimensionner l'objet selon son objet parent.

## Composant Button

Un **bouton** classique, Unity en fournit deux versions : `UI` et `TextMeshPro`. Particularité : le composant `Image` du bouton peut être supprimé sans problème si jugé inutile, par exemple pour des boutons sans fond et n'ayant que du texte.

## Composant Text

[*Learn TextMeshPro*](https://learn.unity.com/tutorial/textmesh-pro-basics "Learn TextMeshPro" _blank)

Ajoutons à notre *canvas* un `UI > Text`.

Il prend en charge des paramètres de fonte, style, etc. 

En particulier, `Best fit` permet de contrôler la taille du texte selon la taille du `GameObject` ; par exemple : les valeurs 14 et 60 définissent les limites de taille de texte quelle que soit la taille de l'objet.

On peut ajouter des composants de `UI > Effets` comme `Shadow` ou `Outline`.

Pour que le texte de ce genre soit lisse à l'écran, cela dépend non pas du texte mais du *canvas*. Par exemple : un *canvas* de `Render mode : World space` et un autre en `Screen Space - Overlay` qui contient du texte. Le premier est très petit par rapport au second. La solution est de sélectionner le *canvas* et de modifier le `Canvas Scaler` : `Dynamic pixels per unit` à 5 ou 10 par exemple.

L'inconvénient de ce procédé est lié au fait que `Text` utilise **une fois pour toute** un bitmap (image pixelisée) pour rendre tout *glyph* de la fonte.

## Composant TextMeshPro

***TextMeshPro*** est un *package* à installer depuis `Window > Package manager > TextMeshPro`. Ce type de texte est plus complet que le `Text` par défaut d'Unity. Il fournit :
- plus de contrôle,
- un générateur de fonte depuis les fontes disponibles dans le *Project* ; aller dans `Window > TextMeshPro > Font Asset Creator`,
- un contrôle sur le texte (*extra settings*, rectangle jaune) indépendant du contrôle de l'objet.

Par exemple, le texte peut avoir un **dégradé (*gradient*)**. Pour ce faire, il faut créer dans *Project* un nouveau `Color gradient`. Puis, dans le composant du texte : cocher la case `Color gradient`, renseigner dans le champ `Color preset` l'*asset* créé.

L'avantage est que `TextMeshPro` utilise le *Signed Distance Fields (SDF) shader* pour **recalculer l'affichage du *glyph* avant d'en faire un bitmap** selon la distance d'affichage. De cette manière, Unity gère aussi du bitmap, ce qui n'a aucun impact sur les performances ; mais cela est **indépendant** de la résolution d'écran, du zoom, de l'échelle.

[*Learn Font asset creation*](https://learn.unity.com/tutorial/textmesh-pro-font-asset-creation "Learn Font asset creation" _blank)

## Composant Image

La **texture** est une image importée dans le *Project* et configurée en vue d'un usage (*sprite*, *cursor*...). On peut la plaquer sur un objet directement, ce qui définit l'albedo de l'objet. Si une texture est paramétrée comme *sprite*, alors ce *sprite* peut être affiché avec le composant `Sprite Renderer`, ce qui conduit à réaliser un objet pour l'affichage 2D. Avec l'*UI*, c'est différent.

La ***Raw image*** est réservée pour l'*UI* et dépend du *canvas* (son *renderer* est le *canvas*). Elle ne prend en charge qu'une **texture**.

Une ***Image*** est réservée pour l'*UI* et dépend du *canvas* (son *renderer* est le *canvas*). Elle permet d'afficher un *sprite* avec des options :
- ***Simple*** : une seule image dans le cadre,
- ***Sliced*** : remplissage. L'image est découpée selon les manipulations effectuées dans *Sprite Editor*,
- ***Tiled*** : pavage et remplissage. Idem précédent mais les parties de remplissages sont répétées,
- ***Filled*** : contrôle sur remplissage horizontal ou vertical ou radial.

## Composant Panel 

On peut **organiser** l'*UI* dans la *Hierarchy* par **écran**. Pour cela, on utilise dans le *canvas* des objets vides ou bien des `Panel` comme autant d'écrans, et on y place tous les objets enfants nécessaires. 

L'organisation peut aller au-delà des contenus du *canvas*, par exemple en dédiant des **scènes** à des écrans d'*UI*.

## Autres composants

- `Toggle` : case à cacher avec label, coche et fond,
- `Toggles groups` : permet de réaliser des boutons radios ; créer un nouveau `GameObject` auquel ajouter le composant `ToggleGroup` puis dans chaque `Toggle` il faut préciser quel `group` utiliser,
- `Slider` : barre avec poignée de déplacement, proposant des valeurs min/max qui peuvent être autre chose que 0/1 ; `Whole numbers` permet d'utiliser ces valeurs en nombre entier ou à virgule flottante,
- `Dropdown` : menu déroulant,
- `Scrollbar` : barre de défilement,
- `Input field` : champ de saisie,
- `ScrollView` : zone d’affichage dont l'enfant `Content` reçoit les éléments à afficher et scroller si besoin.

L'UI peut aussi prendre en charge l'affichage de vidéo grâce au composant `Video > Video player`.

## *Responsive design*

Le *responsive design* est une méthode de conception où l'interface graphique **s'adapte** aux dimensions, résolution, *pixel ratio* de l'écran et ce en temps réel. Dans Unity, cela s'effectue au moyen des **ancres (*anchors*)** et des ***layout groups***.

## Ancres 

Les **ancres** se configurent dans le composant `Rect Transform`, le gros carré.
- Paramètre par défaut : modifier le point d'ancrage relatif au parent, qui peut être subdivisé pour étirer (`stretch`),
- avec `Shift` : modification du pivot en plus,
- avec `Alt` : positionner au point d'ancrage en plus.

## *Layout groups*

Les ***groups*** sont des `GameObjet` ayant le composant `Components > Layout > Grid layout group`. Ensuite, sélectionner `Child alignment : Middle Center` et `Constraint : Flexible` (pour des dimensions déterminées, préférer éventuellements les paramètres `Fixed`). Ajouter ensuite des images dans cet objet et redimensionner cet objet : les enfants se repositionnent en fonction de leur nombre et de la distribution choisie. Une fois l'encombrement maximum atteint, les objets dépassent du parent ; on peut alors redimensionner le `group` ou paramétrer son `Cell size` pour ajuster.

Il existe aussi des *layout groups* orientés par axe : `Horizontal Layout Group` et `Vertical Layout Group`.

## *Canvas group*

Par défaut, chaque objet d'*UI* est indépendant. Cela signifie que, par exemple, changer la couleur ou la transparence d'un élément ne se répercute pas en cascade sur les objets enfants. 

Unity propose un composant `Canvas Group` qui permet à une hiérarchie d'objets de se comporter comme un seul objet. La propriété `Alpha` a été pensée pour réaliser des fondus enchaînés : la transparence y est répercutée sur les objets enfants.

## *Sorting*

On peut ***trier*** les plans d'*UI* en ajoutant autant de *canvas* que nécessaires les uns sur les autres (exemple : le texte toujours sur l'image). On peut aussi ajouter un composant `Canvas` pour définir cette distribution.

Posons 2 *canvas* et une image dans l'un et image dans l'autre. Comment définir l'ordre ? 
- Changer l'ordre dans la *Hierarchy* ne fonctionne pas.
- Alors, sélectionner un *canvas* et définir le paramètre `Sort Order` à un nombre plus grand que l'autre pour le passer devant.

Posons dans un *canvas* deux images l'une sur l'autre. Comment définir l'ordre d'affichage ? 
- Changer l'ordre des deux images dans la *Hierarchy* fonctionne.
- Ou bien ajouter un composant `Layout > Canvas` aux images et cocher `Override Sorting`, ce qui fournit un champ `Sort order` accueillant un nombre entier permettant de définir l'ordre d'affichage du premier plan au dernier plan par ordre décroissant.

## *Layers*

Les ***layers*** permettent de définir ce qui doit être vu ou caché par la caméra. Par exemple : 
- Dans la caméra du monde, dans `Culling mask` ne pas sélectionner `UI` (s'il y en , la caméra ne le verra pas).
- Si la caméra possède une image en objet enfant, définir le *layer* de cet enfant à `Default` pour qu'il apparaisse comme image de fond de la caméra.

## Interactivité

L'interactivité vient des scripts que l'on appelle depuis chaque objet d'*UI*, comme les boutons. On peut :
- créer **un script par objet**,
- ou bien **centraliser toutes les fonctions** dans un seul attaché comme composant au *canvas* ou à un objet dédié *UIController*... 
- ou appeler des **fonctions déjà prévues** à partir des composants d'*UI*,
- ou **mélanger les façons de faire**,
- ou encore faire autrement... c'est selon le **besoins** et les **habitudes**.

Les **appels de fonction** s'effectuent dans le composant de l'objet, par exemple `OnClick()` d'un `Button`. On y renseigne dans le champ la référence de l'objet ayant le composant script et on choisit dans le menu déroulant la fonction `public` désirée. C'est la méthode préconisée par Unity car elle est facile, rapide, elle permet le travail d'équipe avec des non-codeurs... **Attention** : ces blocs d'événements ne permettent que des **fonctions ne prenant au maximum qu'1 seul paramètre**, ce qui peut s'avérer parfois problématique. Cette méthode repose sur les ***Unity Events***.

Exemple : on veut un bouton réagissant à l'événement `onClick` :
- créer une fonction `public` quelque part,
- dans le comportement du bouton, dans `On Click()`, cliquer sur `+`,
- renseigner dans le champ le composant ou objet où le script se trouve,
- dans le menu déroulant, choisir la fonction.

Astuce : la méthode précédente autorise les références par exemple de composants `AudioSource`, que l'on peut `Play()` sans avoir à créer de nouveau script car Unity fournit dans le menu déroulant les méthodes spécifiques et `public` pour le composant renseigné. Dans le même ordre d'idée, le champ peut accueillir une référence au *canvas*. Alors, la liste des fonctions disponibles couvre tous les composants de ce dernier. On y trouvera par exemple  `GameObject > SetActive(bool)` qui permet d'activer/désactiver non l'objet actuel mais le `canvas` passé en référence et ce sans avoir à coder quoi que ce soit. Par conséquent, il faut veiller à bien sélectionner l'objet car il est autant la **référence** que la **cible** du comportement.

Exemple : on veut un bouton réagissant à l'événement de survol de la souris :
- créer une fonction `public` quelque part, 
- sélectionner le bouton et ajouter le composant `Event > Event Trigger`,
- ajouter un `New Event Type` et choisir `Pointer Enter`,
- dans la liste faire comme précédemment : renseigner la référence du script et la fonction.

Exemple : à partir de l'exemple précédent, on veut aussi le *drag 'n drop* :
- ajouter des `New event type` : `Drag` et `EndDrag`,
- coder des fonctions afférentes à chaque événement,
- les renseigner dans chaque bloc d'événement,
- le script de `drag` par exemple :

```C#
[SerializeField] private Canvas _canvas;
private Vector2 _position;

public void onDrag()
{
	RectTransformUtility.ScreenPointToLocalPointInRectangle(_canvas.transform as RectTransform, Input.mousePosition, _canvas.worldCamera, out _position);
	transform.position = _canvas.transform.TransformPoint(_position);
}
```

Sur un `Slider` ou un `Toggle`, lorsqu’on ajoute une fonction au gestionnaire `OnValueChanged`, on peut choisir entre `Dynamic` et `Static`. Pour que cela fonctionne, il faut que la fonction prenne en paramètre une variable du **type** de la valeur de l'élément. Par exemple avec un `Slider` :
- `Dynamic` : **lien avec la valeur** du `Slider`,
- `Static` : définition des valeurs dans la fonction personnelle **sans lien à la valeur** du `Slider`.

```C#
public void TestSlider(float value) 
{
	//...
}
```

## Code

Pour manipuler :
- un composant `TextMeshPro` : 
	- **librairie** `using TMPro;`, 
	- **type** d'objet par exemple `TextMeshProUGUI`,
- un composant d'`UI` : 
	- **librairie** `using UnityEngine.UI;`,
	- **type** d'objet par exemple `Button`.

Exemples de récupération de valeur selon le type de composant d'*UI* :

```C#
float sliderValue = GetComponent<Slider>().value;
```

```C#
bool toggleIsOn = GetComponent<Toggle>().isOn;
```

Outre la méthode préconisée par Unity, il est tout à fait possible de **coder complètement l'interactivité** :
- ajouter différents boutons, 
- leur ajouter le même composant `script`, par exemple :

```C#
using System.Collections;
using System.Collections.Generic;
using UnityEngine;
using UnityEngine.UI; // nécessaire

public class MesBoutons : MonoBehaviour
{
	private Button button;

	private void Start()
	{
		button = GetComponent<Button>();
		button.onClick.AddListener(direBonjour); // définir l'écouteur d'événement onClick appelant la fonction DireBonjour() SANS parenthèses car on veut référer à la fonction et non déclencher cette fonction
	}

	void DireBonjour()
	{
		Debug.Log(button.gameObject.name + " a été cliqué.");
	}
}
```

## Manette et clavier

Unity prend en charge la **navigation** à la manette ou aux touches clavier. 

Pour cela, cliquer sur un bouton et cliquer sur `Visualize` : des flèches jaunes apparaissent indiquant le parcours **automatique**, calculé par Unity.

Le menu déroulant `Navigation` propose d'autres options, notamment `Explicit` qui permet d'indiquer quel est le prochain objets à sélectioner en fonction du type d'entrée utilisateur.

On peut déclarer `Explicit` un bouton mais pas le suivant si ce dernier en `Automatic` agit comme attendu.

Pour les manettes, il faut déclarer quel est le premier bouton sélectionné. Cela s'effectue dans l'`Event System` et le champ `First selected`. Cela se contrôle aussi par code.

Egalement dans l'`Event System`, le composant `Standalone Input Module` permet de définir quel entrée utiliser, entrées que l'on définit dans `Edit > Project Settings > Input Manager`. Exemple (générant de la confusion) : définir l'entrée `Vertical` pour le contrôle par axe horizontal.
